import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,d as i,o as n}from"./app-ROPDmvpc.js";const o="/assets/image-20250227134405866-DrFS3w4f.png",r="/assets/image-20250227140541024-DUA8c0B4.png",s="/assets/image-20250227140855615-zkukafIP.png",p="/assets/image-20250227141203386-DY-7vugf.png",d="/assets/image-20250227151201544-D1iF6vU9.png",g="/assets/image-20250227151506880-X_232jzL.png",c="/assets/image-20250227152205282-Bj2M2j-C.png",l="/assets/image-20250227152632333-DBYLAtLM.png",f="/assets/image-20250227153828426-Cq7mFUd1.png",h="/assets/image-20250227154543863-55Pk5ut4.png",m="/assets/image-20250227155021990-D9lImCr0.png",u="/assets/image-20250227155157347-CQ7hASZ4.png",_="/assets/image-20250227155929250-VPRf_EGc.png",b="/assets/image-20250227160046532-DX7dSA58.png",y="/assets/image-20250227160155392-CilsYkZC.png",x="/assets/image-20250227160357142-BSI-MOWT.png",A="/assets/image-20250227160837247-BuQTgfsY.png",B="/assets/image-20250227161118930--vm-Wmqy.png",k="/assets/image-20250227161210692-BmB136Ll.png",I="/assets/image-20250227170008866-BeX6kaTb.png",z="/assets/image-20250227170701427-B-89ySkG.png",P="/assets/image-20250227171023594-D1nyBPsK.png",D="/assets/image-20250227171240976-CEXCJ8Dl.png",S="/assets/image-20250227171833206-CRfleI2U.png",G="/assets/image-20250227172031377-BuFxbA_H.png",C="/assets/image-20250228105650059-BRO-x8UG.png",R="/assets/image-20250228110537019-zUZaQ7l5.png",w="/assets/image-20250228110639148-C1GuZgu_.png",E="/assets/image-20250228110918357-J8t7uqag.png",v="/assets/image-20250228111246103-CW2iwuHV.png",T="/assets/image-20250228111403748-Cg0bt1Lz.png",O="/assets/image-20250228131013692-BkgDeurZ.png",U="/assets/image-20250228131221231-BWpO5VfV.png",K="/assets/image-20250228132343349-4WsKQOlK.png",M="/assets/image-20250228132656852-C1VFyPyj.png",Y="/assets/image-20250228133447379-N6ckEGzv.png",Z="/assets/image-20250228133644819-BY3pURYh.png",Q={};function W(X,t){return n(),a("div",null,t[0]||(t[0]=[i('<h2 id="使用云端大模型" tabindex="-1"><a class="header-anchor" href="#使用云端大模型"><span>使用云端大模型</span></a></h2><h3 id="硅基流动账户配置" tabindex="-1"><a class="header-anchor" href="#硅基流动账户配置"><span>硅基流动账户配置</span></a></h3><h4 id="账号注册" tabindex="-1"><a class="header-anchor" href="#账号注册"><span>账号注册</span></a></h4><p>可以通过<a href="https://cloud.siliconflow.cn/i/QARWrBHv" target="_blank" rel="noopener noreferrer">此链接</a>进行账号注册。</p><figure><img src="'+o+'" alt="硅基流动注册页面" tabindex="0" loading="lazy"><figcaption>硅基流动注册页面</figcaption></figure><p>可以直接输入手机号进行注册或登录。</p><h4 id="api-密钥生成" tabindex="-1"><a class="header-anchor" href="#api-密钥生成"><span>API 密钥生成</span></a></h4><figure><img src="'+r+'" alt="硅基流动主页面" tabindex="0" loading="lazy"><figcaption>硅基流动主页面</figcaption></figure><p>登录后在左侧侧边栏选择 <code>API 密钥</code> 选项</p><figure><img src="'+s+'" alt="硅基流动API密钥管理页面" tabindex="0" loading="lazy"><figcaption>硅基流动API密钥管理页面</figcaption></figure><p>在 API 密钥页面在右上角选择 <code>新建API密钥</code> 。</p><figure><img src="'+p+'" alt="image-20250227141203386" tabindex="0" loading="lazy"><figcaption>image-20250227141203386</figcaption></figure><p>之后在弹出的对话框里输入待生成密钥的备注，之后点击 <code>新建密钥</code> 按钮即可。之后就会生成如上图所示的密钥了（刚注册的账户是没有密钥的）。</p><h3 id="用户端软件配置" tabindex="-1"><a class="header-anchor" href="#用户端软件配置"><span>用户端软件配置</span></a></h3><h4 id="windows-平台" tabindex="-1"><a class="header-anchor" href="#windows-平台"><span>Windows 平台</span></a></h4><h5 id="cherry-studio-安装" tabindex="-1"><a class="header-anchor" href="#cherry-studio-安装"><span>Cherry Studio 安装</span></a></h5><p>安装 <a href="https://cherry-ai.com/" target="_blank" rel="noopener noreferrer">Cherry Studio</a> 客户端。如果点击 <code>立即下载</code> 后下载速度很慢或者无法下载，请点击 <code>其他版本或备用路线下载</code> ，之后任选一个链接来下载。</p><figure><img src="'+d+'" alt="备用下载页面" tabindex="0" loading="lazy"><figcaption>备用下载页面</figcaption></figure><h5 id="添加-ai-模型" tabindex="-1"><a class="header-anchor" href="#添加-ai-模型"><span>添加 AI 模型</span></a></h5><p>安装完成后打开 Cherry Studio 客户端。之后点击侧边栏左下角的设置选项。</p><figure><img src="'+g+'" alt="Cherry Studio客户端主页面" tabindex="0" loading="lazy"><figcaption>Cherry Studio客户端主页面</figcaption></figure><p>进入设置页面后，请确认菜单栏 1、2 是按如下选择的。之后在 3 处粘贴之前生成的密钥（复制密钥流程见下图）。</p><figure><img src="'+c+'" alt="Cherry Studio客户端设置页面" tabindex="0" loading="lazy"><figcaption>Cherry Studio客户端设置页面</figcaption></figure><figure><img src="'+l+'" alt="复制密钥" tabindex="0" loading="lazy"><figcaption>复制密钥</figcaption></figure><figure><img src="'+f+'" alt="复制密钥成功" tabindex="0" loading="lazy"><figcaption>复制密钥成功</figcaption></figure><p>之后点在 <code>模型广场</code> 页面选择并点击 <code>deepseek-ai/DeepSeek-R1-Distill-Qwen-7B</code> 模型。</p><figure><img src="'+h+'" alt="选择模型" tabindex="0" loading="lazy"><figcaption>选择模型</figcaption></figure><p>然后点击复制按钮复制模型名称。</p><figure><img src="'+m+'" alt="复制模型名称" tabindex="0" loading="lazy"><figcaption>复制模型名称</figcaption></figure><figure><img src="'+u+'" alt="复制模型名称成功" tabindex="0" loading="lazy"><figcaption>复制模型名称成功</figcaption></figure><p>之后在 Cherry Studio 里的设置页面的右边第三个内容框里往下滑动到底，点击 <code>添加</code> 按钮，把刚才复制的模型名称填写到第一个框中（剩余框会自动填充），最后点击 <code>添加模型</code> 按钮。</p><figure><img src="'+_+'" alt="添加模型" tabindex="0" loading="lazy"><figcaption>添加模型</figcaption></figure><figure><img src="'+b+'" alt="填写模型名称" tabindex="0" loading="lazy"><figcaption>填写模型名称</figcaption></figure><figure><img src="'+y+'" alt="填写完成" tabindex="0" loading="lazy"><figcaption>填写完成</figcaption></figure><figure><img src="'+x+'" alt="添加模型成功" tabindex="0" loading="lazy"><figcaption>添加模型成功</figcaption></figure><p>在设置页面点击 <code>默认模型</code> 选项，之后把 2、3、4 依次改成 <code>deepseek-ai/DeepSeek-R1-Distill-Qwen-7B</code> 。</p><figure><img src="'+A+'" alt="更改对话模型" tabindex="0" loading="lazy"><figcaption>更改对话模型</figcaption></figure><figure><img src="'+B+'" alt="选择对话模型" tabindex="0" loading="lazy"><figcaption>选择对话模型</figcaption></figure><figure><img src="'+k+'" alt="更改模型成功" tabindex="0" loading="lazy"><figcaption>更改模型成功</figcaption></figure><h5 id="使-ai-具备网络搜索功能-可选" tabindex="-1"><a class="header-anchor" href="#使-ai-具备网络搜索功能-可选"><span>使 AI 具备网络搜索功能（可选）</span></a></h5><p>点击设置页面的 <code>网络搜索</code>（1）选项，然后点击 <code>点击这里获取密钥选项</code>（2）或者点击<a href="https://app.tavily.com/home" target="_blank" rel="noopener noreferrer">这里</a>，使用邮箱（3）或 Google 账号（1）或 Github 账号（2）注册。</p><figure><img src="'+I+'" alt="网络搜索界面" tabindex="0" loading="lazy"><figcaption>网络搜索界面</figcaption></figure><figure><img src="'+z+'" alt="tavily注册" tabindex="0" loading="lazy"><figcaption>tavily注册</figcaption></figure><p>注册完成之后点击复制按钮来复制 KEY，之后将 KEY 粘贴到 Cherry Studio 里面。</p><figure><img src="'+P+'" alt="复制KEY" tabindex="0" loading="lazy"><figcaption>复制KEY</figcaption></figure><figure><img src="'+D+'" alt="粘贴KEY" tabindex="0" loading="lazy"><figcaption>粘贴KEY</figcaption></figure><h5 id="选择-ai-模型" tabindex="-1"><a class="header-anchor" href="#选择-ai-模型"><span>选择 AI 模型</span></a></h5><p>点击（1）处，选择 <code>deepseek-ai/DeepSeek-R1-Distill-Qwen-7B</code> 模型。如果设置了网络搜索功能，则可以点击（2）开启网络搜索功能。</p><figure><img src="'+S+'" alt="对话页面" tabindex="0" loading="lazy"><figcaption>对话页面</figcaption></figure><figure><img src="'+G+'" alt="模型选择弹窗" tabindex="0" loading="lazy"><figcaption>模型选择弹窗</figcaption></figure><h4 id="android-安卓-平台" tabindex="-1"><a class="header-anchor" href="#android-安卓-平台"><span>Android（安卓）平台</span></a></h4><h5 id="chatbox-安装" tabindex="-1"><a class="header-anchor" href="#chatbox-安装"><span>Chatbox 安装</span></a></h5><p>点击<a href="https://chatboxai.app/zh/install?download=android_apk" target="_blank" rel="noopener noreferrer">此处</a>下载 APK 安装包或访问<a href="https://chatboxai.app/zh" target="_blank" rel="noopener noreferrer">官网</a>下载。之后点击下载好的 APK 来安装软件。</p><h5 id="参数配置" tabindex="-1"><a class="header-anchor" href="#参数配置"><span>参数配置</span></a></h5><p>进入软件后会有一个弹窗，选择 <code>使用自己的 API Key 或本地模型</code>。</p><figure><img src="'+C+'" alt="Chatbox主页面弹窗" tabindex="0" loading="lazy"><figcaption>Chatbox主页面弹窗</figcaption></figure><p>在新弹窗选择 <code>SiliconFlow API</code> 。</p><figure><img src="'+R+'" alt="模型API选择" tabindex="0" loading="lazy"><figcaption>模型API选择</figcaption></figure><p>把<a href="https://cloud.siliconflow.cn/account/ak" target="_blank" rel="noopener noreferrer">硅基流动的密钥</a>粘贴到如下的框中。</p><figure><img src="'+w+'" alt="填入密钥" tabindex="0" loading="lazy"><figcaption>填入密钥</figcaption></figure><p>之后点击下拉菜单栏（1），在选项里下划找到 <code>deepseek-ai/DeepSeek-R1-Distill-Qwen-7B</code>（2）模型，然后点击 <code>保存</code> 即可。</p><figure><img src="'+E+'" alt="模型选择" tabindex="0" loading="lazy"><figcaption>模型选择</figcaption></figure><p>点击如下所示按钮即可开启模型联网功能。</p><figure><img src="'+v+'" alt="开启联网功能" tabindex="0" loading="lazy"><figcaption>开启联网功能</figcaption></figure><figure><img src="'+T+'" alt="启用联网功能成功" tabindex="0" loading="lazy"><figcaption>启用联网功能成功</figcaption></figure><h2 id="使用本地大模型" tabindex="-1"><a class="header-anchor" href="#使用本地大模型"><span>使用本地大模型</span></a></h2><h3 id="安装-ollama" tabindex="-1"><a class="header-anchor" href="#安装-ollama"><span>安装 Ollama</span></a></h3><p>访问<a href="https://ollama.com/" target="_blank" rel="noopener noreferrer">官网</a>下载安装</p><figure><img src="'+O+'" alt="Ollama官网" tabindex="0" loading="lazy"><figcaption>Ollama官网</figcaption></figure><p>安装完成后在 CMD 中输入 <code>ollama -v</code> 验证安装是否成功</p><figure><img src="'+U+'" alt="ollama 版本" tabindex="0" loading="lazy"><figcaption>ollama 版本</figcaption></figure><h3 id="拉取模型" tabindex="-1"><a class="header-anchor" href="#拉取模型"><span>拉取模型</span></a></h3><p>根据个人电脑配置选择模型</p><table><thead><tr><th>模型版本</th><th>参数量</th><th>显存需求（FP16）</th><th>推荐 GPU（单卡）</th><th>多卡支持</th><th>量化支持</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>DeepSeek-R1-1.5B</strong></td><td>15亿</td><td>3GB</td><td>GTX 1650（4GB显存）</td><td>无需</td><td>支持</td><td>低资源设备部署（树莓派、旧款笔记本）、实时文本生成、嵌入式系统</td></tr><tr><td><strong>DeepSeek-R1-7B</strong></td><td>70亿</td><td>14GB</td><td>RTX 3070/4060（8GB显存）</td><td>可选</td><td>支持</td><td>中等复杂度任务（文本摘要、翻译）、轻量级多轮对话系统</td></tr><tr><td><strong>DeepSeek-R1-8B</strong></td><td>80亿</td><td>16GB</td><td>RTX 4070（12GB显存）</td><td>可选</td><td>支持</td><td>需更高精度的轻量级任务（代码生成、逻辑推理）</td></tr><tr><td><strong>DeepSeek-R1-14B</strong></td><td>140亿</td><td>32GB</td><td>RTX 4090/A5000（16GB显存）</td><td>推荐</td><td>支持</td><td>企业级复杂任务（合同分析、报告生成）、长文本理解与生成</td></tr><tr><td><strong>DeepSeek-R1-32B</strong></td><td>320亿</td><td>64GB</td><td>A100 40GB（24GB显存）</td><td>推荐</td><td>支持</td><td>高精度专业领域任务（医疗/法律咨询）、多模态任务预处理</td></tr><tr><td><strong>DeepSeek-R1-70B</strong></td><td>700亿</td><td>140GB</td><td>2x A100 80GB/4x RTX 4090（多卡并行）</td><td>必需</td><td>支持</td><td>科研机构/大型企业（金融预测、大规模数据分析）、高复杂度生成任务</td></tr><tr><td><strong>DeepSeek-671B</strong></td><td>6710亿</td><td>512GB+（单卡显存需求极高，通常需要多节点分布式训练）</td><td>8x A100/H100（服务器集群）</td><td>必需</td><td>支持</td><td>国家级/超大规模 AI 研究（气候建模、基因组分析）、通用人工智能（AGI）探索</td></tr></tbody></table><p>更多版本可以查看<a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noopener noreferrer">这里</a> 。</p><p>我的电脑配置是</p><table><thead><tr><th>System</th><th>Windows 11 专业版</th></tr></thead><tbody><tr><td>CPU</td><td>12th Gen Intel<sup>®</sup> Core™ i7-12700F</td></tr><tr><td>RAM</td><td>32G</td></tr><tr><td>GPU</td><td>NVIDIA<sup>®</sup> GeForce RTX™ 3060 12G</td></tr><tr><td>Disk</td><td>SAMSUNG MZVL4512HBLU-00BL7 512G</td></tr></tbody></table><figure><img src="'+K+'" alt="电脑概况" tabindex="0" loading="lazy"><figcaption>电脑概况</figcaption></figure><p>所以我选择的是 <strong>DeepSeek-R1-8B</strong>。</p><figure><img src="'+M+'" alt="选取模型" tabindex="0" loading="lazy"><figcaption>选取模型</figcaption></figure><p>命令行输入 <code>ollama run deepseek-r1:8b</code> 拉取 DeepSeek 模型。几分钟后安装完成就可以在控制台进行对话了。</p><h3 id="配置交互页面-可选" tabindex="-1"><a class="header-anchor" href="#配置交互页面-可选"><span>配置交互页面（可选）</span></a></h3><p>使用命令提示符与 DeepSeek 对话并不友好，为了更好的体验，我们可以安装 <a href="https://webui.me/" target="_blank" rel="noopener noreferrer">WebUI</a>。</p><p>命令行输入 <code>pip install open-webui</code> 即可安装。但需注意，Python 版本需要 3.11 及以上。</p><p>完成后，输入 <code>open-webui serve</code> 即可看到如下界面。</p><figure><img src="'+Y+'" alt="open webui控制台界面" tabindex="0" loading="lazy"><figcaption>open webui控制台界面</figcaption></figure><p>再打开 <code>http://localhost:8080/</code> 选取模型后就可以使用了。</p><figure><img src="'+Z+'" alt="open webui网络界面" tabindex="0" loading="lazy"><figcaption>open webui网络界面</figcaption></figure>',88)]))}const V=e(Q,[["render",W],["__file","AI模型搭建.html.vue"]]),N=JSON.parse('{"path":"/posts/%E6%95%99%E7%A8%8B/AI%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA.html","title":"通过硅基流动来搭建自己的AI模型","lang":"zh-CN","frontmatter":{"title":"通过硅基流动来搭建自己的AI模型","date":"2025-02-27T00:00:00.000Z","category":"教程","tag":["Deepseek"],"description":"使用云端大模型 硅基流动账户配置 账号注册 可以通过此链接进行账号注册。 硅基流动注册页面硅基流动注册页面 可以直接输入手机号进行注册或登录。 API 密钥生成 硅基流动主页面硅基流动主页面 登录后在左侧侧边栏选择 API 密钥 选项 硅基流动API密钥管理页面硅基流动API密钥管理页面 在 API 密钥页面在右上角选择 新建API密钥 。 image...","head":[["meta",{"property":"og:url","content":"https://mioor.top/posts/%E6%95%99%E7%A8%8B/AI%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA.html"}],["meta",{"property":"og:site_name","content":"MIOOR"}],["meta",{"property":"og:title","content":"通过硅基流动来搭建自己的AI模型"}],["meta",{"property":"og:description","content":"使用云端大模型 硅基流动账户配置 账号注册 可以通过此链接进行账号注册。 硅基流动注册页面硅基流动注册页面 可以直接输入手机号进行注册或登录。 API 密钥生成 硅基流动主页面硅基流动主页面 登录后在左侧侧边栏选择 API 密钥 选项 硅基流动API密钥管理页面硅基流动API密钥管理页面 在 API 密钥页面在右上角选择 新建API密钥 。 image..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-02-28T07:11:21.000Z"}],["meta",{"property":"article:author","content":"MIOOR"}],["meta",{"property":"article:tag","content":"Deepseek"}],["meta",{"property":"article:published_time","content":"2025-02-27T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-02-28T07:11:21.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"通过硅基流动来搭建自己的AI模型\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-02-27T00:00:00.000Z\\",\\"dateModified\\":\\"2025-02-28T07:11:21.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"MIOOR\\",\\"url\\":\\"http://mioor.top\\"}]}"]]},"headers":[{"level":2,"title":"使用云端大模型","slug":"使用云端大模型","link":"#使用云端大模型","children":[{"level":3,"title":"硅基流动账户配置","slug":"硅基流动账户配置","link":"#硅基流动账户配置","children":[]},{"level":3,"title":"用户端软件配置","slug":"用户端软件配置","link":"#用户端软件配置","children":[]}]},{"level":2,"title":"使用本地大模型","slug":"使用本地大模型","link":"#使用本地大模型","children":[{"level":3,"title":"安装 Ollama","slug":"安装-ollama","link":"#安装-ollama","children":[]},{"level":3,"title":"拉取模型","slug":"拉取模型","link":"#拉取模型","children":[]},{"level":3,"title":"配置交互页面（可选）","slug":"配置交互页面-可选","link":"#配置交互页面-可选","children":[]}]}],"git":{"createdTime":1740721845000,"updatedTime":1740726681000,"contributors":[{"name":"MIOOR","email":"yangwenyao07@gmail.com","commits":3}]},"readingTime":{"minutes":6.8,"words":2039},"filePathRelative":"posts/教程/AI模型搭建.md","localizedDate":"2025年2月27日","excerpt":"<h2>使用云端大模型</h2>\\n<h3>硅基流动账户配置</h3>\\n<h4>账号注册</h4>\\n<p>可以通过<a href=\\"https://cloud.siliconflow.cn/i/QARWrBHv\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">此链接</a>进行账号注册。</p>\\n<figure><figcaption>硅基流动注册页面</figcaption></figure>\\n<p>可以直接输入手机号进行注册或登录。</p>\\n<h4>API 密钥生成</h4>\\n<figure><figcaption>硅基流动主页面</figcaption></figure>","autoDesc":true}');export{V as comp,N as data};
